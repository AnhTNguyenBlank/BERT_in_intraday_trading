{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a874fc-cde5-421c-9ce5-fa29657960b5",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390f32dc-525e-4272-9e1c-5259d53cdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('classic')\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062b7a08-bd63-4bb8-a417-fd54fa6f32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'D:/BERT_in_intraday_trading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd486a22-ddda-4d28-a304-4bf14e7ee902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.support import *\n",
    "from src.backtest import *\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd163c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f32596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "# from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba65158-e1f2-4f9f-a867-beb1960e6f8a",
   "metadata": {},
   "source": [
    "# Import and pre-processing news data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727780a",
   "metadata": {},
   "source": [
    "## News_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/BERT_in_intraday_trading/Training/Data/stored_data.pkl\", \"rb\") as f:\n",
    "    news_data = pickle.load(f)\n",
    "\n",
    "# cnt = 0\n",
    "\n",
    "# for new in news_data:\n",
    "#     if new['CONTENT'] == 'content':\n",
    "#         cnt += 1\n",
    "\n",
    "# print(cnt, len(news_data))\n",
    "\n",
    "news_data = [new for new in news_data if new['CONTENT'] != 'content']\n",
    "news_data = pd.DataFrame(news_data)\n",
    "news_data.set_index(keys = 'TIME_POSTED', inplace = True)\n",
    "news_data.index = pd.to_datetime(news_data.index).tz_localize(None)\n",
    "news_data = news_data[~news_data.index.isna()].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc697dd-2579-4d0c-9445-a9a536274807",
   "metadata": {},
   "source": [
    "## Interval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de595335-c8b7-4a00-9323-80b96a840c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_data = pd.read_pickle('D:/BERT_in_intraday_trading/Training/Data/XAUUSDm_M1.pkl')\n",
    "\n",
    "interval_data = interval_data.set_index('DATE_TIME')\n",
    "interval_data.index = pd.to_datetime(interval_data.index)\n",
    "\n",
    "interval_data['DATE'] = pd.to_datetime(interval_data['DATE'])\n",
    "interval_data['OPEN'] = interval_data['OPEN']\n",
    "interval_data['HIGH'] = interval_data['HIGH']\n",
    "interval_data['LOW'] = interval_data['LOW']\n",
    "interval_data['CLOSE'] = interval_data['CLOSE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bd551-c4c4-4d15-b638-0327ec995547",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prepare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a86c3b-fa28-48bf-b532-b86425b6644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_min = prepare_df(df = interval_data, timeframe = '1min', add_indicators = True)\n",
    "\n",
    "df_1_min['WHOLE_RANGE'] = df_1_min['HIGH'] - df_1_min['LOW']\n",
    "df_1_min['GRP_WHOLE_RANGE'] = pd.qcut(df_1_min['WHOLE_RANGE'], 10)\n",
    "df_1_min['GRP_BODY'] = pd.qcut(df_1_min['BODY'], 10)\n",
    "df_1_min['YEAR'] = df_1_min.index.strftime('%Y')\n",
    "df_1_min['WEEK'] = df_1_min.index.strftime('%Y%W')  \n",
    "df_1_min['MONTH'] = df_1_min.index.strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40eca3f-3b98-497e-88db-7c974cebd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d84add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_min.index[0], df_1_min.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51674bdf-0908-446c-b5d8-575f9de4b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df(df_1_min, \n",
    "#         path = None,# 'D:/Intraday_trading/Training/Saved_results/plot_df.html', \n",
    "#         open_tab = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a25c7",
   "metadata": {},
   "source": [
    "## Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb585a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['MEAN_BA'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name - pd.Timedelta(hours = 4)) & (df_1_min.index <= x.name + pd.Timedelta(hours = 4)), 'Ret(t)'].mean(), axis = 1)\n",
    "news_data['VAR_BA'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name - pd.Timedelta(hours = 4)) & (df_1_min.index <= x.name + pd.Timedelta(hours = 4)), 'Ret(t)'].var(), axis = 1)\n",
    "\n",
    "news_data['MEAN_B'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name - pd.Timedelta(hours = 4)) & (df_1_min.index <= x.name), 'Ret(t)'].mean(), axis = 1)\n",
    "news_data['VAR_B'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name - pd.Timedelta(hours = 4)) & (df_1_min.index <= x.name), 'Ret(t)'].var(), axis = 1)\n",
    "\n",
    "news_data['MEAN_A'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name) & (df_1_min.index <= x.name + pd.Timedelta(hours = 4)), 'Ret(t)'].mean(), axis = 1)\n",
    "news_data['VAR_A'] = news_data.apply(lambda x: df_1_min.loc[(df_1_min.index >= x.name) & (df_1_min.index <= x.name + pd.Timedelta(hours = 4)), 'Ret(t)'].var(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61163f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['RATIO_VAR_A_B'] = news_data['VAR_A']/news_data['VAR_B']\n",
    "news_data['RATIO_MEAN_A_B'] = news_data['MEAN_A']/news_data['MEAN_B']\n",
    "news_data['FLAG_HIGH_RISK'] = news_data['RATIO_VAR_A_B'].apply(lambda x: 1 if x >= news_data['RATIO_VAR_A_B'].quantile(0.75) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227db80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['FLAG_HIGH_RISK'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c877298",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.to_pickle('D:/BERT_in_intraday_trading/Training/Data/news_data_w_labels.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b39bb4",
   "metadata": {},
   "source": [
    "# Import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d23ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_pickle(\"D:/BERT_in_intraday_trading/Training/Data/news_data_w_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3eb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = news_data['CONTENT']\n",
    "labels = news_data[['RATIO_VAR_A_B', 'RATIO_MEAN_A_B', 'FLAG_HIGH_RISK']]\n",
    "\n",
    "# Split\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size = 0.7, \n",
    "    random_state = 12345, shuffle = False\n",
    "    )\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size = 0.5, \n",
    "    random_state = 12345, shuffle = False)\n",
    "\n",
    "# Wrap into datasets\n",
    "def prepare_labeled_dataset(texts, labels, batch_size = 32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
    "    ds = ds.shuffle(buffer_size=len(texts))\n",
    "    ds = ds.batch(batch_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_labeled_dataset(train_texts, train_labels)\n",
    "val_ds = prepare_labeled_dataset(val_texts, val_labels)\n",
    "test_ds = prepare_labeled_dataset(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ea1584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-4-h-512-a-8/2\n",
      "Preprocess model auto-selected: https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "# tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "# tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "tfhub_handle_encoder = 'https://kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-4-h-512-a-8/2'\n",
    "tfhub_handle_preprocess = 'https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3'\n",
    "\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59146460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b37971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-4-h-512-a-8/2\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.76262873  0.9928099  -0.18611842  0.36673835  0.15233713  0.6550445\n",
      "  0.9681154  -0.94862705  0.00216199 -0.9877732   0.06842697 -0.97630596]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.28946307  0.3432126   0.33231524 ...  0.21300834  0.71020776\n",
      "  -0.05771159]\n",
      " [-0.28742072  0.31980997 -0.23018596 ...  0.5845511  -0.21329741\n",
      "   0.7269215 ]\n",
      " [-0.66157013  0.6887673  -0.8743302  ...  0.10877225 -0.26173237\n",
      "   0.47855318]\n",
      " ...\n",
      " [-0.22561178 -0.2892561  -0.07064433 ...  0.4756602   0.83277094\n",
      "   0.4002539 ]\n",
      " [-0.29824233 -0.27473113 -0.05450515 ...  0.48849773  1.0955355\n",
      "   0.18163365]\n",
      " [-0.4437818   0.00930784  0.07223748 ...  0.17290097  1.183325\n",
      "   0.07897963]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3f04bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text_input')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name = 'text_preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable = True, name = 'BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.3)(net)\n",
    "  FLAG_HIGH_RISK = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'FLAG_high_risk')(net)\n",
    "  RATIO_MEAN = tf.keras.layers.Dense(1, activation = None, name = 'RATIO_MEAN')(net)\n",
    "  RATIO_VAR = tf.keras.layers.Dense(1, activation = 'relu', name = 'RATIO_VAR')(net)\n",
    "  \n",
    "  return tf.keras.Model(text_input, [FLAG_HIGH_RISK, RATIO_MEAN, RATIO_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df0026c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61b5179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text_input (InputLayer)        [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_preprocessing (KerasLayer  {'input_type_ids':   0          ['text_input[0][0]']             \n",
      " )                              (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['text_preprocessing[0][0]',     \n",
      "                                512),                             'text_preprocessing[0][1]',     \n",
      "                                 'encoder_outputs':               'text_preprocessing[0][2]']     \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512)}                                                       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " FLAG_high_risk (Dense)         (None, 1)            513         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " RATIO_MEAN (Dense)             (None, 1)            513         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " RATIO_VAR (Dense)              (None, 1)            513         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,765,188\n",
      "Trainable params: 28,765,187\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18d4e1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.4708895]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.57016623]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_raw_result = classifier_model(tf.constant([news_data['CONTENT'][0]]))\n",
    "bert_raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11c4642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics = tf.metrics.MeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea27a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=init_lr,\n",
    "#     weight_decay=0.01\n",
    "# )\n",
    "\n",
    "classifier_model.compile(optimizer = 'adam',\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e41a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-4-h-512-a-8/2\n",
      "74/74 [==============================] - 183s 2s/step - loss: nan - FLAG_high_risk_loss: nan - RATIO_MEAN_loss: nan - RATIO_VAR_loss: nan - FLAG_high_risk_mean_absolute_percentage_error: nan - RATIO_MEAN_mean_absolute_percentage_error: nan - RATIO_VAR_mean_absolute_percentage_error: nan - val_loss: nan - val_FLAG_high_risk_loss: nan - val_RATIO_MEAN_loss: nan - val_RATIO_VAR_loss: nan - val_FLAG_high_risk_mean_absolute_percentage_error: nan - val_RATIO_MEAN_mean_absolute_percentage_error: nan - val_RATIO_VAR_mean_absolute_percentage_error: nan\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "198c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 45s 513ms/step - loss: nan - FLAG_high_risk_loss: nan - RATIO_MEAN_loss: nan - RATIO_VAR_loss: nan - FLAG_high_risk_mean_absolute_percentage_error: nan - RATIO_MEAN_mean_absolute_percentage_error: nan - RATIO_VAR_mean_absolute_percentage_error: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m classifier_model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'news_data'\n",
    "saved_model_path = 'D:/BERT_in_intraday_trading/Training/Saved_results/{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ea53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloaded_model = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "# def print_my_examples(inputs, results):\n",
    "#   result_for_printing = \\\n",
    "#     [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "#                          for i in range(len(inputs))]\n",
    "#   print(*result_for_printing, sep='\\n')\n",
    "#   print()\n",
    "\n",
    "\n",
    "# examples = [\n",
    "#     'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
    "#     'The movie was great!',\n",
    "#     'The movie was meh.',\n",
    "#     'The movie was okish.',\n",
    "#     'The movie was terrible...'\n",
    "# ]\n",
    "\n",
    "# reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "# print('Results from the saved model:')\n",
    "# print_my_examples(examples, reloaded_results)\n",
    "# print('Results from the model in memory:')\n",
    "# print_my_examples(examples, original_results)\n",
    "\n",
    "\n",
    "# serving_results = reloaded_model \\\n",
    "#             .signatures['serving_default'](tf.constant(examples))\n",
    "\n",
    "# serving_results = tf.sigmoid(serving_results['classifier'])\n",
    "\n",
    "# print_my_examples(examples, serving_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
